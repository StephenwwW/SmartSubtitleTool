import tkinter as tk
from tkinter import filedialog, ttk, messagebox
import threading
import os
import time
import subprocess
import logging
import json
import queue
import gc
import tempfile
import numpy as np
import re

# --- ä¾è³´å¥—ä»¶æª¢æŸ¥å‡½å¼ ---
def check_dependencies():
    """æª¢æŸ¥æ‰€æœ‰å¿…è¦çš„å¥—ä»¶ã€‚"""
    errors = []
    try:
        import torch
    except ImportError as e:
        errors.append(f"- PyTorch ç„¡æ³•è¼‰å…¥: {e}")
    try:
        from moviepy.editor import VideoFileClip, AudioFileClip
    except ImportError as e:
        errors.append(f"- MoviePy ç„¡æ³•è¼‰å…¥: {e}")
    try:
        from translation_module import generate_bilingual_srt_content
    except ImportError as e:
        errors.append(f"- Translation Module ç„¡æ³•è¼‰å…¥: {e}")
    try:
        from faster_whisper import WhisperModel
    except ImportError as e:
        errors.append(f"- Faster-Whisper ç„¡æ³•è¼‰å…¥: {e}")
    try:
        import pysrt
    except ImportError as e:
        errors.append(f"- PySRT ç„¡æ³•è¼‰å…¥: {e}")
    return errors

# --- å…¨åŸŸè¨­å®š ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# --- è¼”åŠ©å‡½å¼ ---
def load_config(path="config.json"):
    if not os.path.exists(path):
        return None, f"è¨­å®šæª” '{path}' ä¸å­˜åœ¨ã€‚"
    try:
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f), None
    except Exception as e:
        return None, f"è®€å–è¨­å®šæª” '{path}' å¤±æ•—: {e}"

def time_to_seconds(time_str):
    try:
        h, m, s_float = time_str.split(':')
        s, ms = map(int, s_float.replace(',', '.').split('.'))
        return int(h) * 3600 + int(m) * 60 + s + ms / 1000.0
    except:
        try:
            h, m, s = map(int, time_str.split(':'))
            return h * 3600 + m * 60 + s
        except ValueError:
            return 0

def seconds_to_time(seconds):
    h, remainder = divmod(seconds, 3600)
    m, s = divmod(remainder, 60)
    return f"{int(h):02}:{int(m):02}:{int(s):02}"

def filter_segments_by_energy(segments, audio_path, energy_threshold=0.005):
    """
    [v3.0 ä¿®æ­£] é€éæ›´ç©©å¥çš„æ–¹å¼è®€å–éŸ³è¨Šï¼Œé¿å… moviepy ç”¢ç”Ÿéé æœŸè³‡æ–™çµæ§‹ã€‚
    """
    try:
        from moviepy.editor import AudioFileClip
        logging.info(f"[è³‡è¨Š] æ­£åœ¨é€²è¡ŒéŸ³è¨Šèƒ½é‡åˆ†æä»¥éæ¿¾å¹»è½...")
        
        with AudioFileClip(audio_path) as clip:
            # ç¢ºä¿éŸ³è¨Šä»¥ 16000Hz å–®è²é“è®€å–
            audio_array = clip.to_soundarray(fps=16000, nbytes=2)
            if not isinstance(audio_array, np.ndarray):
                 raise TypeError("MoviePy did not return a numpy array.")

        if audio_array.ndim > 1:
            audio_array = audio_array.mean(axis=1) # è½‰ç‚ºå–®è²é“
            
        sample_rate = 16000
        filtered_segments = []
        for seg in segments:
            start_sample = int(seg["start"] * sample_rate)
            end_sample = int(seg["end"] * sample_rate)
            
            # ç¢ºä¿åˆ‡ç‰‡ç¯„åœæœ‰æ•ˆ
            if start_sample >= end_sample or start_sample >= len(audio_array):
                continue
            end_sample = min(end_sample, len(audio_array))
            
            segment_audio = audio_array[start_sample:end_sample]
            
            if segment_audio.size == 0:
                continue

            rms_energy = np.sqrt(np.mean(np.square(segment_audio.astype(np.float32))))
            
            if rms_energy >= energy_threshold:
                filtered_segments.append(seg)
            else:
                logging.info(f"[èƒ½é‡éæ¿¾] æ¨æ£„ä½èƒ½é‡ç‰‡æ®µ: \"{seg['text']}\" (èƒ½é‡: {rms_energy:.4f})")
        
        logging.info(f"[è³‡è¨Š] èƒ½é‡åˆ†æå®Œæˆï¼ŒåŸå§‹ {len(segments)} æ®µï¼Œéæ¿¾å¾Œå‰©ä¸‹ {len(filtered_segments)} æ®µã€‚")
        return filtered_segments
    except Exception as e:
        logging.warning(f"[è­¦å‘Š] éŸ³è¨Šèƒ½é‡åˆ†æå¤±æ•—: {e}ã€‚å°‡è·³éæ­¤éæ¿¾æ­¥é©Ÿã€‚")
        return segments

# --- ä¸»æ‡‰ç”¨ç¨‹å¼é¡åˆ¥ ---
class SubtitleApp:
    def __init__(self, root, dependency_errors):
        self.root = root
        self.root.title("æ™ºæ…§å­—å¹•å·¥å…· v3.0 (ç©©å®šç‰ˆ)")
        self.root.geometry("520x650")

        self.config, config_error = load_config()
        if config_error:
            messagebox.showerror("è¨­å®šéŒ¯èª¤", config_error)
            self.root.destroy(); return
        
        self.prompt_config, prompt_error = load_config("prompt_config.json")
        if prompt_error:
            messagebox.showwarning("Prompt è¨­å®šè­¦å‘Š", f"{prompt_error}\nå°‡ä½¿ç”¨é è¨­çš„ç°¡æ˜“ç¿»è­¯æŒ‡ä»¤ã€‚")
            
        self.video_path = None
        self.is_processing = False
        self.gui_queue = queue.Queue()

        self.mode_var = tk.StringVar(value="accurate")
        self.use_time_range = tk.BooleanVar(value=False)
        self.start_time_var = tk.StringVar(value="00:00:00")
        self.end_time_var = tk.StringVar(value="00:00:00")
        self.translation_model_var = tk.StringVar()
        self.cpu_precision_var = tk.StringVar(value="float32")
        self.detected_lang = None

        self.create_widgets()
        self.process_queue()
        
        self.dependencies_ok = not dependency_errors
        if not self.dependencies_ok:
            self.mode_radio_accurate.config(state=tk.DISABLED)
            self.mode_radio_fast.config(state=tk.DISABLED)
            messagebox.showwarning("ç¼ºå°‘å¥—ä»¶", f"ä¸€å€‹æˆ–å¤šå€‹æ ¸å¿ƒå¥—ä»¶ç„¡æ³•è¼‰å…¥ï¼ŒåŠŸèƒ½å°‡å—é™ã€‚\n\nè©³ç´°è³‡è¨Š:\n" + "\n".join(dependency_errors))

    def create_widgets(self):
        main_frame = tk.Frame(self.root, padx=10, pady=10)
        main_frame.pack(fill=tk.BOTH, expand=True)

        self.progress_var = tk.DoubleVar()
        self.progress_bar = ttk.Progressbar(main_frame, variable=self.progress_var, maximum=100)
        self.progress_bar.pack(pady=5, fill="x")
        self.status_label = tk.Label(main_frame, text="è«‹é¸æ“‡åª’é«”æª”æ¡ˆ...", font=("Arial", 12))
        self.status_label.pack(pady=5)
        self.btn_select_video = tk.Button(main_frame, text="é¸æ“‡å½±ç‰‡æˆ–éŸ³è¨Š", command=self.select_video)
        self.btn_select_video.pack(pady=5)

        mode_frame = tk.LabelFrame(main_frame, text="è™•ç†æ¨¡å¼", padx=10, pady=5)
        mode_frame.pack(pady=10, fill="x")
        self.mode_radio_fast = tk.Radiobutton(mode_frame, text="ğŸš€ å¿«é€Ÿæ¨¡å¼ (whisper.cpp)", variable=self.mode_var, value="fast")
        self.mode_radio_fast.pack(side="left", padx=5)
        self.mode_radio_accurate = tk.Radiobutton(mode_frame, text="ğŸ¯ ç²¾æº–æ¨¡å¼ (faster-whisper)", variable=self.mode_var, value="accurate")
        self.mode_radio_accurate.pack(side="left", padx=5)

        time_frame = tk.LabelFrame(main_frame, text="æ™‚é–“ç¯„åœ", padx=10, pady=10)
        time_frame.pack(pady=10, fill="x")
        time_frame.columnconfigure(1, weight=1)
        time_frame.columnconfigure(3, weight=1)
        
        self.use_time_range_cb = tk.Checkbutton(time_frame, text="ä½¿ç”¨æ™‚é–“ç¯„åœ", variable=self.use_time_range)
        self.use_time_range_cb.grid(row=0, column=0, columnspan=4, sticky="w")
        tk.Label(time_frame, text="é–‹å§‹:").grid(row=1, column=0, sticky="w", padx=5)
        self.start_time_entry = tk.Entry(time_frame, textvariable=self.start_time_var, width=10)
        self.start_time_entry.grid(row=1, column=1, sticky="w")
        tk.Label(time_frame, text="çµæŸ:").grid(row=1, column=2, sticky="w", padx=5)
        self.end_time_entry = tk.Entry(time_frame, textvariable=self.end_time_var, width=10)
        self.end_time_entry.grid(row=1, column=3, sticky="w")
        self.video_duration_label = tk.Label(time_frame, text="ç¸½æ™‚é•·: N/A")
        self.video_duration_label.grid(row=2, column=0, columnspan=4, sticky="w", pady=(5,0))

        options_frame = tk.LabelFrame(main_frame, text="é€²éšé¸é … (åƒ…é™ç²¾æº–æ¨¡å¼)", padx=10, pady=10)
        options_frame.pack(pady=10, fill="x")
        
        cpu_precision_frame = tk.Frame(options_frame)
        cpu_precision_frame.pack(anchor="w", pady=2)
        tk.Label(cpu_precision_frame, text="CPU é‹ç®—ç²¾åº¦:").pack(side="left")
        self.precision_radio_fast = tk.Radiobutton(cpu_precision_frame, text="é«˜æ•ˆèƒ½ (int8)", variable=self.cpu_precision_var, value="int8")
        self.precision_radio_fast.pack(side="left", padx=5)
        self.precision_radio_accurate = tk.Radiobutton(cpu_precision_frame, text="æœ€é«˜ç²¾åº¦ (float32)", variable=self.cpu_precision_var, value="float32")
        self.precision_radio_accurate.pack(side="left", padx=5)

        translation_frame = tk.LabelFrame(main_frame, text="ç¿»è­¯æ¨¡å‹é¸æ“‡", padx=10, pady=10)
        translation_frame.pack(pady=10, fill="x")
        tk.Label(translation_frame, text="ä½¿ç”¨æ¨¡å‹:").pack(side="left", padx=5)
        self.translation_model_menu = ttk.Combobox(translation_frame, textvariable=self.translation_model_var, state="readonly")
        self.translation_model_menu.pack(fill="x", expand=True)
        self.update_translation_model_menu()

        self.btn_transcribe = tk.Button(main_frame, text="é–‹å§‹ç”Ÿæˆå­—å¹•", command=self.start_processing_thread, font=("Arial", 12, "bold"), height=2, width=15, state=tk.DISABLED)
        self.btn_transcribe.pack(pady=10)
        
    def update_translation_model_menu(self, lang_code=None):
        self.detected_lang = lang_code
        lang_key = lang_code if lang_code and lang_code in self.config.get("translation_models", {}) else "mixed"
        models = self.config.get("translation_models", {}).get(lang_key, [])
        model_names = [m.get("name") for m in models if m.get("name")]
        self.translation_model_menu['values'] = model_names
        self.translation_model_var.set(model_names[0] if model_names else "")

    def process_queue(self):
        try:
            while True:
                msg_type, value = self.gui_queue.get_nowait()
                if msg_type == "status": self.status_label.config(text=value)
                elif msg_type == "progress": self.progress_var.set(value)
                elif msg_type == "processing_done": self.toggle_controls(True)
                elif msg_type == "set_duration":
                    self.video_duration_label.config(text=f"ç¸½æ™‚é•·: {value}")
                    self.end_time_var.set(value)
                elif msg_type == "language_detected":
                    self.update_translation_model_menu(value)
                    status_msg = f"åµæ¸¬åˆ°èªè¨€: {value}ã€‚è«‹é¸æ“‡ç¿»è­¯æ¨¡å‹ã€‚" if value else "èªè¨€åµæ¸¬å¤±æ•—ï¼Œå°‡ä½¿ç”¨é è¨­æ¨¡å‹ã€‚"
                    self.update_status(status_msg)
                    self.btn_transcribe.config(state=tk.NORMAL)
        except queue.Empty:
            pass
        self.root.after(100, self.process_queue)

    def toggle_controls(self, enabled):
        state = tk.NORMAL if enabled else tk.DISABLED
        self.is_processing = not enabled
        for widget in [self.btn_select_video, self.mode_radio_fast, self.mode_radio_accurate,
                       self.use_time_range_cb, self.start_time_entry, self.end_time_entry,
                       self.translation_model_menu, self.precision_radio_fast, self.precision_radio_accurate]:
            widget.config(state=state)
        self.btn_transcribe.config(state=tk.NORMAL if enabled and self.video_path else tk.DISABLED)

    def select_video(self):
        file_path = filedialog.askopenfilename(filetypes=[("åª’é«”æª”æ¡ˆ", "*.mp4;*.mkv;*.mov;*.avi;*.mp3;*.wav"), ("æ‰€æœ‰æª”æ¡ˆ", "*.*")])
        if file_path:
            self.video_path = file_path
            self.update_status(f"å·²é¸æ“‡: {os.path.basename(self.video_path)}")
            self.btn_transcribe.config(state=tk.DISABLED)
            threading.Thread(target=self.get_video_info_worker, args=(file_path,), daemon=True).start()

    def get_video_info_worker(self, file_path):
        try:
            from moviepy.editor import VideoFileClip
            with VideoFileClip(file_path) as clip:
                duration = clip.duration
            duration_str = seconds_to_time(duration)
            self.gui_queue.put(("set_duration", duration_str))
            self.update_status("æ­£åœ¨åµæ¸¬èªè¨€ï¼Œè«‹ç¨å€™...")
            self.detect_language_worker(file_path)
        except Exception as e:
            logging.error(f"è®€å–å½±ç‰‡è³‡è¨Šå¤±æ•—: {e}")
            self.update_status("ç„¡æ³•è®€å–å½±ç‰‡è³‡è¨Š")
            self.gui_queue.put(("set_duration", "N/A"))
            self.gui_queue.put(("language_detected", None))

    def detect_language_worker(self, file_path):
        temp_audio_path = None
        logging.info("--- é–‹å§‹èªè¨€åµæ¸¬ ---")
        try:
            from moviepy.editor import VideoFileClip
            from faster_whisper import WhisperModel
            temp_dir = tempfile.gettempdir()
            temp_audio_path = os.path.join(temp_dir, f"lang_detect_temp_{int(time.time())}.wav")
            with VideoFileClip(file_path) as clip:
                clip.subclip(0, min(clip.duration, 30)).audio.write_audiofile(temp_audio_path, codec='pcm_s16le', logger=None)
            model = WhisperModel("base", device="cpu", compute_type="int8")
            _, info = model.transcribe(temp_audio_path, beam_size=5)
            self.gui_queue.put(("language_detected", info.language))
        except Exception as e:
            logging.error(f"èªè¨€åµæ¸¬å¤±æ•—: {e}")
            self.gui_queue.put(("language_detected", None))
        finally:
            if temp_audio_path and os.path.exists(temp_audio_path): os.remove(temp_audio_path)
            logging.info("--- èªè¨€åµæ¸¬çµæŸ ---")
    
    def update_status(self, text):
        self.gui_queue.put(("status", text))

    def update_progress(self, value):
        self.gui_queue.put(("progress", value))

    def start_processing_thread(self):
        if not self.video_path:
            messagebox.showerror("éŒ¯èª¤", "è«‹å…ˆé¸æ“‡ä¸€å€‹åª’é«”æª”æ¡ˆã€‚")
            return
        self.toggle_controls(False)
        worker = self.fast_mode_worker if self.mode_var.get() == "fast" else self.accurate_mode_worker
        threading.Thread(target=worker, daemon=True).start()
    
    def build_output_path(self):
        video_dir = os.path.dirname(self.video_path)
        base_filename = os.path.splitext(os.path.basename(self.video_path))[0]
        mode_tag = self.mode_var.get()
        # å–æ¨¡å‹åç¨±ä½œç‚ºæª”åæ¨™ç±¤ï¼Œç§»é™¤ä¸åˆæ³•å­—å…ƒä¸¦æˆªçŸ­
        model_tag_raw = self.translation_model_var.get() or "model"
        model_tag = re.sub(r"[^A-Za-z0-9\-_]", "", model_tag_raw)[:40]
        return os.path.join(video_dir, f"{base_filename}_{mode_tag}_{model_tag}.srt")

    def fast_mode_worker(self):
        logging.info("--- é–‹å§‹å¿«é€Ÿæ¨¡å¼è™•ç† (å¹»è½ä¿®æ­£ç‰ˆ) ---")
        temp_audio_path = None
        try:
            cli_path = self.config["whisper_cpp"]["cli_path"]
            model_path = self.config["whisper_cpp"]["model_path"]
            if not all(map(os.path.exists, [cli_path, model_path])):
                raise FileNotFoundError(f"whisper-cli æˆ–æ¨¡å‹è·¯å¾‘ä¸å­˜åœ¨ï¼Œè«‹æª¢æŸ¥ config.jsonã€‚\nCLI: {cli_path}\nModel: {model_path}")
            
            self.update_status("å¿«é€Ÿæ¨¡å¼ï¼šæ­£åœ¨æå–éŸ³è¨Š...")
            from moviepy.editor import AudioFileClip
            import pysrt
            
            temp_dir = tempfile.gettempdir()
            temp_audio_path = os.path.join(temp_dir, f"temp_audio_{int(time.time())}.wav")
            logging.info(f"å»ºç«‹è‡¨æ™‚éŸ³è¨Šæª”æ–¼: {temp_audio_path}")
            
            start_s, duration = None, None
            if self.use_time_range.get():
                start_s = time_to_seconds(self.start_time_var.get())
                end_s = time_to_seconds(self.end_time_var.get())
                duration = end_s - start_s
            with AudioFileClip(self.video_path) as clip:
                audio_clip = clip.subclip(start_s, start_s + duration) if start_s is not None else clip.audio
                audio_clip.write_audiofile(temp_audio_path, codec='pcm_s16le', logger=None)
            
            self.update_status("å¿«é€Ÿæ¨¡å¼ï¼šæ­£åœ¨é€²è¡ŒèªéŸ³è¾¨è­˜...")
            raw_srt_path = temp_audio_path + ".srt" 
            
            command = [
                cli_path, "-m", model_path, "-f", temp_audio_path, "-osrt",
                "-l", self.detected_lang or "auto", "-t", "8",
                "--vad-filter", "true", "--vad-threshold", "0.5",
                "--max-len", "20", "--word-threshold", "0.4",
                "--entropy-threshold", "2.4", "--logprob-threshold", "-1.0",
                "--no-timestamps", "false", "--beam-size", "5",
                "--best-of", "5", "--temperature", "0.0"
            ]
            logging.info(f"åŸ·è¡Œå‘½ä»¤: {' '.join(command)}")

            process = subprocess.Popen(
                command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, 
                encoding='utf-8', errors='ignore', bufsize=1, env=os.environ
            )
            
            while True:
                output_line = process.stdout.readline()
                if not output_line and process.poll() is not None: break
                if output_line: logging.info(f"[whisper.cpp]: {output_line.strip()}")
            
            return_code = process.wait()
            if return_code != 0:
                stderr_output = process.stderr.read()
                raise subprocess.CalledProcessError(return_code, command, stderr=stderr_output)

            if not os.path.exists(raw_srt_path):
                raise FileNotFoundError(f"Whisper.cpp æœªèƒ½æˆåŠŸç”Ÿæˆ SRT æª”æ¡ˆ ({raw_srt_path})ã€‚")

            subs = pysrt.open(raw_srt_path, encoding='utf-8')
            segments = [{"start": s.start.seconds + s.start.milliseconds / 1000.0, 
                         "end": s.end.seconds + s.end.milliseconds / 1000.0, 
                         "text": s.text} for s in subs]
            
            segments = filter_segments_by_energy(segments, temp_audio_path)
            self.update_status("å¿«é€Ÿæ¨¡å¼ï¼šæ­£åœ¨ç¿»è­¯å­—å¹•...")
            from translation_module import generate_bilingual_srt_content, clear_caches
            bilingual_content = generate_bilingual_srt_content(segments, self.config, self.translation_model_var.get(), self.detected_lang, self.prompt_config)
            
            output_path = self.build_output_path()
            with open(output_path, "w", encoding="utf-8") as f: f.write(bilingual_content)
            
            self.update_progress(100)
            self.update_status("å¿«é€Ÿæ¨¡å¼è™•ç†å®Œæˆï¼")
            messagebox.showinfo("å®Œæˆ", f"å­—å¹•å·²æˆåŠŸç”Ÿæˆï¼\nè·¯å¾‘:\n{output_path}")
        except subprocess.CalledProcessError as e:
            logging.exception("å¿«é€Ÿæ¨¡å¼è™•ç†å¤±æ•—:")
            error_message = f"å¿«é€Ÿæ¨¡å¼è™•ç†å¤±æ•—ï¼Œwhisper-cli.exe å‚³å›éŒ¯èª¤ã€‚\n\néŒ¯èª¤ç¢¼: {e.returncode}\n\nè©³ç´°è³‡è¨Š:\n{e.stderr}"
            self.update_status(f"éŒ¯èª¤: whisper-cli.exe åŸ·è¡Œå¤±æ•—")
            messagebox.showerror("éŒ¯èª¤", error_message)
        except Exception as e:
            logging.exception("å¿«é€Ÿæ¨¡å¼è™•ç†å¤±æ•—:")
            self.update_status(f"éŒ¯èª¤: {e}")
            messagebox.showerror("éŒ¯èª¤", f"å¿«é€Ÿæ¨¡å¼è™•ç†å¤±æ•—:\n{e}")
        finally:
            if temp_audio_path and os.path.exists(temp_audio_path): os.remove(temp_audio_path)
            raw_srt_path = (temp_audio_path or "") + ".srt"
            if os.path.exists(raw_srt_path): os.remove(raw_srt_path)
            if 'clear_caches' in locals(): clear_caches()
            self.gui_queue.put(("processing_done", None))

    def accurate_mode_worker(self):
        logging.info("--- é–‹å§‹ç²¾æº–æ¨¡å¼è™•ç† (å¹»è½ä¿®æ­£ç‰ˆ) ---")
        temp_audio_path = None
        model = None
        try:
            import torch
            from moviepy.editor import VideoFileClip, AudioFileClip
            from faster_whisper import WhisperModel
            from translation_module import generate_bilingual_srt_content, clear_caches

            self.update_status("æº–å‚™ç’°å¢ƒ...")
            device = "cuda" if torch.cuda.is_available() else "cpu"
            
            compute_type = self.cpu_precision_var.get() if device == "cpu" else self.config["whisperx_model"]["compute_type"]
            model_size = self.config["whisperx_model"]["model_name"]
            logging.info(f"ç’°å¢ƒæº–å‚™å®Œæˆ (æ¨¡å‹: {model_size}, è£ç½®: {device}, è¨ˆç®—é¡å‹: {compute_type})ã€‚")

            self.update_status(f"è¼‰å…¥éŸ³è¨Š...")
            audio_path_for_model = self.video_path
            if self.use_time_range.get():
                start_s = time_to_seconds(self.start_time_var.get())
                end_s = time_to_seconds(self.end_time_var.get())
                temp_dir = tempfile.gettempdir()
                temp_audio_path = os.path.join(temp_dir, f"temp_audio_{int(time.time())}.wav")
                with AudioFileClip(self.video_path) as clip:
                    clip.subclip(start_s, end_s).audio.write_audiofile(temp_audio_path, codec='pcm_s16le', logger=None)
                audio_path_for_model = temp_audio_path

            self.update_status(f"è¾¨è­˜èˆ‡åˆ†æ®µä¸­ (æ¨¡å‹: {model_size})...")
            model = WhisperModel(model_size, device=device, compute_type=compute_type)
            
            segments_iterator, _ = model.transcribe(audio_path_for_model, 
                                                    language=self.detected_lang,
                                                    beam_size=5,
                                                    vad_filter=True,
                                                    vad_parameters=dict(min_silence_duration_ms=500, threshold=0.6))

            initial_segments = [{"start": s.start, "end": s.end, "text": s.text} for s in segments_iterator]
            if not initial_segments: raise ValueError("æ¨¡å‹æœªèƒ½è¾¨è­˜å‡ºä»»ä½•èªéŸ³ç‰‡æ®µã€‚")
            
            self.update_status("æ­£åœ¨é€²è¡Œèƒ½é‡åˆ†æä»¥éæ¿¾å¹»è½...")
            final_segments = filter_segments_by_energy(initial_segments, audio_path_for_model)
            if not final_segments:
                raise ValueError("æ‰€æœ‰èªéŸ³ç‰‡æ®µå› èƒ½é‡éä½è¢«éæ¿¾ï¼Œå¯èƒ½ç‚ºéœéŸ³æˆ–ç´”å™ªéŸ³ã€‚")

            self.update_status("æ­£åœ¨ç¿»è­¯å­—å¹•...")
            bilingual_content = generate_bilingual_srt_content(final_segments, self.config, self.translation_model_var.get(), self.detected_lang, self.prompt_config)
            
            output_path = self.build_output_path()
            with open(output_path, "w", encoding="utf-8") as f: f.write(bilingual_content)
            
            self.update_progress(100)
            self.update_status("ç²¾æº–æ¨¡å¼è™•ç†å®Œæˆï¼")
            messagebox.showinfo("å®Œæˆ", f"å­—å¹•å·²æˆåŠŸç”Ÿæˆï¼\nè·¯å¾‘:\n{output_path}")
        except Exception as e:
            logging.exception("ç²¾æº–æ¨¡å¼è™•ç†å¤±æ•—:")
            self.update_status(f"éŒ¯èª¤: {e}")
            messagebox.showerror("éŒ¯èª¤", f"ç²¾æº–æ¨¡å¼è™•ç†å¤±æ•—:\n{e}")
        finally:
            logging.info("æ­£åœ¨æ¸…ç†æš«å­˜æª”æ¡ˆèˆ‡è¨˜æ†¶é«”...")
            if temp_audio_path and os.path.exists(temp_audio_path): os.remove(temp_audio_path)
            if 'clear_caches' in locals(): clear_caches()
            if model is not None:
                del model
                gc.collect()
                if 'torch' in locals() and torch.cuda.is_available(): torch.cuda.empty_cache()
            self.gui_queue.put(("processing_done", None))

if __name__ == "__main__":
    print("--- æ­£åœ¨æª¢æŸ¥ä¾è³´å¥—ä»¶ ---")
    dependency_errors = check_dependencies()
    print("--- æª¢æŸ¥å ±å‘Š ---")
    if not dependency_errors:
        print("æ‰€æœ‰æ ¸å¿ƒå¥—ä»¶çš†å·²æˆåŠŸè¼‰å…¥ã€‚")
    else:
        for error in dependency_errors:
            print(error)
    print("--------------------")
    root = tk.Tk()
    app = SubtitleApp(root, dependency_errors)
    root.mainloop()
